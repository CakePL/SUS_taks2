{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce45fd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 10:45:03.903184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi951/linux64/lib\n",
      "2022-05-27 10:45:03.903256: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aef2443",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/css_main_training.csv\", sep=\";\")\n",
    "data_test = pd.read_csv(\"data/css_main_test.csv\", sep=\";\")\n",
    "data_fuel = pd.read_csv(\"data/fuel_prices.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba8f72d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_drop = [\"id_contract\", \"id_payer\", \"temperature\", \"route_start_datetime\", \"route_end_datetime\", \"route_start_unix\", \"route_end_unix\", \"date\"]\n",
    "ordinal_cats = [\"load_size_type\", \"contract_type\"]\n",
    "one_hot_cats = [\"direction\", \"route_start_country\", \"last_unload_country\", \"first_load_country\", \"route_end_country\", \"id_currency\", \"prim_train_line\",\n",
    "                \"prim_ferry_line\", \"id_service_type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bbc5a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preproc(df, train=True, enc_one_hot=None, enc_ordinal=None):\n",
    "    if train:\n",
    "        assert(enc_one_hot is None and enc_ordinal is None)\n",
    "    else:\n",
    "        assert(enc_one_hot is not None and enc_ordinal is not None)\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    nan_to_zero = [\"prim_train_line\", \"prim_ferry_line\"]\n",
    "    for col_name in nan_to_zero:\n",
    "        df[col_name] = df.apply(lambda row: 0 if np.isnan(row[col_name]) else row[col_name], axis=1)\n",
    "\n",
    "    df[\"route_start_unix\"] = df.apply(lambda row: time.mktime(datetime.datetime.fromisoformat(row[\"route_start_datetime\"]).timetuple()), axis=1)\n",
    "    df[\"route_end_unix\"] = df.apply(lambda row: time.mktime(datetime.datetime.fromisoformat(row[\"route_end_datetime\"]).timetuple()), axis=1)\n",
    "    df[\"duration\"] = df.apply(lambda row: row[\"route_end_unix\"] - row[\"route_start_unix\"], axis=1)\n",
    "    df[\"date\"] = df.apply(lambda row: row[\"route_start_datetime\"].split()[0], axis=1)\n",
    "\n",
    "    df = df.merge(data_fuel, on=\"date\")\n",
    "\n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    if train:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if train:\n",
    "        df = df.sample(frac=1, random_state=18)\n",
    "\n",
    "    X, y = df.drop(columns=[\"expenses\"] + one_hot_cats + ordinal_cats).to_numpy(), df[\"expenses\"].to_numpy()\n",
    "\n",
    "    df_one_hot_cats = df[one_hot_cats]\n",
    "    if train:\n",
    "        enc_one_hot = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        X_one_hot_cats = enc_one_hot.fit_transform(df_one_hot_cats.to_numpy()).toarray()\n",
    "    else:\n",
    "        X_one_hot_cats = enc_one_hot.transform(df_one_hot_cats.to_numpy()).toarray()\n",
    "    X = np.concatenate((X, X_one_hot_cats), axis=1)\n",
    "\n",
    "    df_ordinal_cats = df[ordinal_cats]\n",
    "    if train:\n",
    "        enc_ordinal = preprocessing.OrdinalEncoder()\n",
    "        X_ordinal_cats = enc_ordinal.fit_transform(df_ordinal_cats.to_numpy())\n",
    "    else:\n",
    "        X_ordinal_cats = enc_ordinal.transform(df_ordinal_cats.to_numpy())\n",
    "    X = np.concatenate((X, X_ordinal_cats), axis=1)\n",
    "\n",
    "\n",
    "    print(X.shape)\n",
    "    if train:\n",
    "        return X, y, enc_one_hot, enc_ordinal\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate(model, X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = metrics.mean_squared_error(y_test, y_pred) ** (1/2)\n",
    "    return -score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_submit(model):\n",
    "    X_train, y_train, enc_one_hot, enc_ordinal = preproc(data_train, train=True)\n",
    "    X_test, _ = preproc(data_test, train=False, enc_one_hot=enc_one_hot, enc_ordinal=enc_ordinal)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    assert(len(y_pred) == len(data_test.index))\n",
    "    print(y_pred)\n",
    "    pd.Series(y_pred).to_csv(f\"result.txt\", sep='\\n', header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train, enc_one_hot, enc_ordinal = preproc(data_train, train=True)\n",
    "X_test, y_test = preproc(data_test, train=False, enc_one_hot=enc_one_hot, enc_ordinal=enc_ordinal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = #TODO!!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate(model, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_submit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}