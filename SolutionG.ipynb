{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce45fd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aef2443",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/css_main_training.csv\", sep=\";\")\n",
    "data_test = pd.read_csv(\"data/css_main_test.csv\", sep=\";\")\n",
    "data_fuel = pd.read_csv(\"data/fuel_prices.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba8f72d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_drop = [\"id_contract\", \"id_payer\", \"temperature\", \"route_start_datetime\", \"route_end_datetime\", \"route_start_unix\", \"route_end_unix\", \"date\"]\n",
    "ordinal_cats = [\"load_size_type\", \"contract_type\"]\n",
    "one_hot_cats = [\"direction\", \"route_start_country\", \"last_unload_country\", \"first_load_country\", \"route_end_country\", \"id_currency\", \"prim_train_line\",\n",
    "                \"prim_ferry_line\", \"id_service_type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50bbc5a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preproc(df, train=True, enc_one_hot=None, enc_ordinal=None):\n",
    "    if train:\n",
    "        assert(enc_one_hot is None and enc_ordinal is None)\n",
    "    else:\n",
    "        assert(enc_one_hot is not None and enc_ordinal is not None)\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    nan_to_zero = [\"prim_train_line\", \"prim_ferry_line\"]\n",
    "    for col_name in nan_to_zero:\n",
    "        df[col_name] = df.apply(lambda row: 0 if np.isnan(row[col_name]) else row[col_name], axis=1)\n",
    "\n",
    "    df[\"route_start_unix\"] = df.apply(lambda row: time.mktime(datetime.datetime.fromisoformat(row[\"route_start_datetime\"]).timetuple()), axis=1)\n",
    "    df[\"route_end_unix\"] = df.apply(lambda row: time.mktime(datetime.datetime.fromisoformat(row[\"route_end_datetime\"]).timetuple()), axis=1)\n",
    "    df[\"duration\"] = df.apply(lambda row: row[\"route_end_unix\"] - row[\"route_start_unix\"], axis=1)\n",
    "    df[\"date\"] = df.apply(lambda row: row[\"route_start_datetime\"].split()[0], axis=1)\n",
    "\n",
    "    df = df.merge(data_fuel, on=\"date\")\n",
    "\n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    if train:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if train:\n",
    "        df = df.sample(frac=1, random_state=18)\n",
    "\n",
    "    X, y = df.drop(columns=[\"expenses\"] + one_hot_cats + ordinal_cats).to_numpy(), df[\"expenses\"].to_numpy()\n",
    "\n",
    "    df_one_hot_cats = df[one_hot_cats]\n",
    "    if train:\n",
    "        enc_one_hot = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        X_one_hot_cats = enc_one_hot.fit_transform(df_one_hot_cats.to_numpy()).toarray()\n",
    "    else:\n",
    "        X_one_hot_cats = enc_one_hot.transform(df_one_hot_cats.to_numpy()).toarray()\n",
    "    X = np.concatenate((X, X_one_hot_cats), axis=1)\n",
    "\n",
    "    df_ordinal_cats = df[ordinal_cats]\n",
    "    if train:\n",
    "        enc_ordinal = preprocessing.OrdinalEncoder()\n",
    "        X_ordinal_cats = enc_ordinal.fit_transform(df_ordinal_cats.to_numpy())\n",
    "    else:\n",
    "        X_ordinal_cats = enc_ordinal.transform(df_ordinal_cats.to_numpy())\n",
    "    X = np.concatenate((X, X_ordinal_cats), axis=1)\n",
    "\n",
    "\n",
    "    print(X.shape)\n",
    "    if train:\n",
    "        return X, y, enc_one_hot, enc_ordinal\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b878c870",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = metrics.mean_squared_error(y_test, y_pred) ** (1/2)\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34bd8f46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_submit(model, name):\n",
    "    X_train, y_train, enc_one_hot, enc_ordinal = preproc(data_train, train=True)\n",
    "    X_test, _ = preproc(data_test, train=False, enc_one_hot=enc_one_hot, enc_ordinal=enc_ordinal)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    assert(len(y_pred) == len(data_test.index))\n",
    "    print(y_pred)\n",
    "    pd.Series(y_pred).to_csv(f\"result{name}.txt\", sep='\\n', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc32cd29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326465, 289)\n",
      "(72452, 289)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, enc_one_hot, enc_ordinal = preproc(data_train, train=True)\n",
    "X_test, y_test = preproc(data_test, train=False, enc_one_hot=enc_one_hot, enc_ordinal=enc_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65446bfa",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ensemble.ExtraTreesRegressor(\n",
    "    n_jobs=-1,\n",
    "    random_state=18,\n",
    "    verbose=1,\n",
    "\n",
    "    n_estimators=330,\n",
    "    max_depth=21,\n",
    "    min_samples_leaf=100,\n",
    "    # max_features=0.98,\n",
    "    max_leaf_nodes=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a47b91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 330 out of 330 | elapsed: 11.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 330 out of 330 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.17808402915550867"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4186e5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a1b750",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326465, 289)\n",
      "(72452, 289)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 330 out of 330 | elapsed: 14.0min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.04428474 4.99381426 7.23042244 ... 4.93177446 4.93177446 7.02306503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 330 out of 330 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "make_submit(model, name=\"var1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
